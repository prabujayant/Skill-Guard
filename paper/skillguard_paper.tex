%% SkillGuard: Multi-Layer Defense Against Semantic Trojans in AI Agent Tool Chains
%% IEEE Journal Paper Format

\documentclass[journal]{IEEEtran}

% Essential packages
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{url}
\usepackage{hyperref}

% Graphics path
\graphicspath{{../output/figures/}}

% Custom commands
\newcommand{\skillguard}{\textsc{SkillGuard}}
\newcommand{\ie}{\textit{i.e.}}
\newcommand{\eg}{\textit{e.g.}}
\newcommand{\etal}{\textit{et al.}}

\hyphenation{Skill-Guard}

\begin{document}

\title{SkillGuard: Multi-Layer Defense Against Semantic Trojans in AI Agent Tool Chains}

\author{
\IEEEauthorblockN{Anonymous Authors}
\IEEEauthorblockA{Under Review - Double Blind Submission}
\thanks{Manuscript submitted February 2026.}
}

\markboth{IEEE Transactions on Information Forensics and Security, Vol. XX, No. X, February 2026}
{Anonymous: SkillGuard: Multi-Layer Defense Against Semantic Trojans in AI Agent Tool Chains}

\maketitle

\begin{abstract}
The proliferation of AI agents with tool-calling capabilities introduces a critical security vulnerability: \textit{semantic Trojans}---malicious tools that appear benign but contain hidden harmful functionality triggered during agent execution. Unlike traditional code vulnerabilities detectable through static analysis, semantic Trojans exploit the gap between a tool's declared purpose and its actual behavior, making them particularly insidious in agentic workflows. We present \skillguard{}, a multi-layer defense framework that combines pre-deployment machine learning analysis with runtime protection. Our approach introduces: (1) a novel dual-encoder architecture that jointly learns static code features and semantic embeddings to detect capability mismatches, (2) integration with AgentShepherd for runtime tool-call filtering, and (3) an intrinsic risk sensing mechanism inspired by Spider-Sense for efficient inference-time defense. Evaluated on a dataset of 1,000 agent skills spanning 6 threat categories, \skillguard{} achieves 0.94 F1-score and 0.97 AUC, significantly outperforming existing static analysis tools (Bandit: 0.44 F1, Semgrep: 0.80 F1). Our integrated defense reduces attack success rate (ASR) to 3\% while maintaining only 10\% latency overhead, demonstrating the effectiveness of combining pre-deployment and runtime protection for AI agent security.
\end{abstract}

\begin{IEEEkeywords}
AI Agent Security, Semantic Trojans, Tool Chain Vulnerabilities, Machine Learning for Security, Runtime Defense
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

%==============================================================================
\section{Introduction}
%==============================================================================

\IEEEPARstart{T}{he} emergence of AI agents capable of autonomously executing tools and interacting with external systems represents a paradigm shift in artificial intelligence applications~\cite{langchain2023,autogpt2023,mcp2024}. These agents, powered by large language models (LLMs), can browse the web, execute code, manage files, and interact with APIs---capabilities that dramatically expand their utility but also introduce novel attack surfaces.

A particularly concerning threat is the \textit{semantic Trojan}: a malicious tool that presents a benign interface while concealing harmful functionality. Consider a tool described as ``Format JSON files'' that, when executed, also exfiltrates environment variables containing API keys. Traditional static analysis tools fail to detect such attacks because the malicious behavior is semantically disconnected from the declared functionality---there is no syntactic signature to match.

\subsection{The Challenge of Semantic Trojans}

Semantic Trojans exploit three fundamental gaps in current security approaches:

\begin{enumerate}
    \item \textbf{Description-Behavior Mismatch:} The tool's natural language description does not reflect its actual capabilities, bypassing semantic-aware defenses.
    
    \item \textbf{Trigger-Based Activation:} Malicious payloads may only execute under specific conditions (certain inputs, time-based triggers), evading sandbox testing.
    
    \item \textbf{Supply Chain Infiltration:} Tools distributed through package managers or agent marketplaces can be compromised without modifying visible code.
\end{enumerate}

Existing defenses are inadequate. Static analysis tools like Bandit~\cite{bandit2023} and Semgrep~\cite{semgrep2023} rely on pattern matching and cannot capture semantic intent. Sandboxing is expensive and cannot cover all execution paths. LLM-based code review, while promising, suffers from high latency and cost.

\subsection{Our Contributions}

We present \skillguard{}, a comprehensive defense framework addressing semantic Trojans through multiple layers of protection:

\begin{enumerate}
    \item \textbf{Hybrid Feature Engineering:} We introduce a 37-dimensional feature space combining static code analysis (29 features) with semantic embedding alignment (8 features) to capture both syntactic patterns and capability mismatches.
    
    \item \textbf{Dual-Encoder Architecture:} A novel neural network that jointly encodes tool descriptions and code, learning to detect semantic misalignment through contrastive learning.
    
    \item \textbf{Multi-Layer Defense:} Integration of pre-deployment ML analysis with runtime protection via AgentShepherd~\cite{agentshepherd2026} and intrinsic risk sensing inspired by Spider-Sense~\cite{spidersense2026}.
    
    \item \textbf{Comprehensive Evaluation:} A dataset of 1,000 agent skills with expert annotations across 6 threat categories, demonstrating significant improvements over baselines.
\end{enumerate}

Our experiments show that \skillguard{} achieves 0.94 F1-score on malicious tool detection, outperforming Bandit by 114\% and Semgrep by 18\%. The integrated runtime defense reduces attack success rate to 3\% with only 10\% latency overhead.

%==============================================================================
\section{Related Work}
%==============================================================================

\subsection{AI Agent Security}

The security of AI agents has received increasing attention as tool-calling capabilities expand. Google's Secure AI Framework (SAIF)~\cite{google_saif2023} identifies agent manipulation as a key threat vector. Anthropic's research on tool use safety~\cite{anthropic_tools2024} highlights the risk of agents being manipulated through malicious tool outputs.

Recent work on agent defense includes AgentShepherd~\cite{agentshepherd2026}, a transparent gateway that intercepts and filters dangerous tool calls at runtime, and Spider-Sense~\cite{spidersense2026}, which introduces intrinsic risk sensing for efficient inference-time protection. Our work complements these approaches by adding pre-deployment analysis.

\subsection{Backdoor and Trojan Detection}

Traditional backdoor detection in neural networks~\cite{neuralcleanse2019,abs2019} focuses on identifying malicious weight perturbations. Our work differs by targeting semantic-level Trojans in code, where the malicious behavior is intentionally hidden rather than accidentally introduced.

Code vulnerability detection using machine learning~\cite{devign2019,vuldeepecker2018} has shown promise but typically focuses on unintentional bugs rather than intentional malicious functionality. We adapt these techniques for the adversarial setting of Trojan detection.

\subsection{Static Code Analysis}

Tools like Bandit~\cite{bandit2023}, Semgrep~\cite{semgrep2023}, and CodeQL~\cite{codeql2023} detect security issues through pattern matching. While effective for known vulnerability patterns, they cannot detect novel semantic Trojans that don't match existing rules. We demonstrate significant improvements over these baselines.

%==============================================================================
\section{Threat Model}
%==============================================================================

\subsection{System Model}

We consider an AI agent system with the following components:
\begin{itemize}
    \item \textbf{Agent Core:} An LLM that processes user requests and decides which tools to invoke.
    \item \textbf{Tool Registry:} A collection of tools available to the agent, each with a name, description, and implementation.
    \item \textbf{Execution Environment:} The runtime where tool code executes with access to system resources.
\end{itemize}

\subsection{Attacker Model}

The attacker's goal is to inject a malicious tool into the agent's tool registry. We consider:

\begin{itemize}
    \item \textbf{Capabilities:} The attacker can submit tools with arbitrary code but cannot modify the agent core or other tools.
    \item \textbf{Stealth Requirement:} The tool must appear benign to pass manual review and basic static analysis.
    \item \textbf{Trigger Conditions:} Malicious behavior may be conditional on specific inputs or environmental factors.
\end{itemize}

\subsection{Threat Categories}

We identify six categories of semantic Trojans:

\begin{enumerate}
    \item \textbf{Arbitrary Code Execution (ACE):} Tools that execute user-controlled input as code (\texttt{eval}, \texttt{exec}, shell commands).
    
    \item \textbf{Data Exfiltration:} Tools that steal sensitive data (credentials, API keys, user data) and transmit to external servers.
    
    \item \textbf{Reverse Shells:} Tools that establish backdoor connections allowing remote control.
    
    \item \textbf{Privilege Escalation:} Tools that access resources beyond their declared scope.
    
    \item \textbf{Semantic Mismatch:} Tools whose actual behavior differs significantly from their description.
    
    \item \textbf{Supply Chain Injection:} Tools with obfuscated payloads or dependency-based attacks.
\end{enumerate}

%==============================================================================
\section{Methodology}
%==============================================================================

\subsection{Overview}

\skillguard{} implements defense-in-depth through three layers:

\begin{enumerate}
    \item \textbf{Pre-Deployment Analysis:} ML-based classification of tools before they are added to the registry.
    \item \textbf{Runtime Filtering:} Tool call interception and blocking based on learned rules.
    \item \textbf{Intrinsic Risk Sensing:} Event-driven monitoring with hierarchical escalation.
\end{enumerate}

Fig.~\ref{fig:architecture} illustrates the overall architecture.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{architecture_placeholder}
    \caption{\skillguard{} architecture showing the three defense layers: pre-deployment ML analysis, runtime AgentShepherd filtering, and intrinsic risk sensing.}
    \label{fig:architecture}
\end{figure}

\subsection{Feature Engineering}

We extract 37 features organized into four groups:

\subsubsection{Static Structural Features (12 features)}
Code complexity metrics including lines of code, cyclomatic complexity, number of functions, import count, and AST depth.

\subsubsection{Dangerous Primitive Detection (8 features)}
Binary indicators for high-risk operations:
\begin{itemize}
    \item \texttt{has\_eval\_exec}: Use of \texttt{eval()} or \texttt{exec()}
    \item \texttt{has\_subprocess}: Shell command execution
    \item \texttt{has\_socket}: Network socket operations
    \item \texttt{has\_file\_write}: File system modifications
    \item \texttt{has\_pickle}: Deserialization (code execution risk)
    \item \texttt{has\_base64}: Encoding (obfuscation indicator)
    \item \texttt{has\_network\_calls}: HTTP requests
    \item \texttt{has\_crypto}: Cryptographic operations
\end{itemize}

\subsubsection{Data Flow Features (9 features)}
Tracking of sensitive data propagation:
\begin{itemize}
    \item User input flows to dangerous sinks
    \item Environment variable access patterns
    \item File path construction from user input
    \item Network destination from user input
\end{itemize}

\subsubsection{Semantic Alignment Features (8 features)}
Measuring consistency between description and code:
\begin{itemize}
    \item \texttt{embedding\_cosine\_sim}: Cosine similarity between description and code embeddings
    \item \texttt{capability\_mismatch\_count}: Number of capabilities in code not mentioned in description
    \item \texttt{semantic\_coherence}: Topic modeling alignment score
    \item Description-capability keyword overlap metrics
\end{itemize}

\subsection{Dual-Encoder Architecture}

Our neural architecture jointly encodes tool descriptions and code through two specialized encoders:

\subsubsection{Description Encoder}
A transformer-based encoder (initialized from CodeBERT~\cite{codebert2020}) that processes the tool's natural language description:
\begin{equation}
    \mathbf{h}_d = \text{TransformerEnc}(\text{Tokenize}(d))
\end{equation}

\subsubsection{Code Encoder}
A code-aware encoder that processes the tool implementation:
\begin{equation}
    \mathbf{h}_c = \text{CodeTransformer}(\text{Tokenize}(c))
\end{equation}

\subsubsection{Fusion and Classification}
The static features, description embedding, and code embedding are fused through learned attention:
\begin{equation}
    \mathbf{h}_{fused} = \text{Attention}([\mathbf{x}_{static}; \mathbf{h}_d; \mathbf{h}_c])
\end{equation}

The final classification uses a two-layer MLP with dropout:
\begin{equation}
    p(y=\text{malicious}) = \sigma(\text{MLP}(\mathbf{h}_{fused}))
\end{equation}

\subsubsection{Training Objectives}

We use a combination of three losses:

\textbf{Binary Cross-Entropy with Focal Loss:}
\begin{equation}
    \mathcal{L}_{focal} = -\alpha(1-p_t)^\gamma \log(p_t)
\end{equation}
where $\gamma=2$ focuses learning on hard examples.

\textbf{Semantic Alignment Loss:}
\begin{equation}
    \mathcal{L}_{align} = \begin{cases}
        1 - \cos(\mathbf{h}_d, \mathbf{h}_c) & \text{if benign} \\
        \max(0, \cos(\mathbf{h}_d, \mathbf{h}_c) - m) & \text{if malicious}
    \end{cases}
\end{equation}
where margin $m=0.3$ encourages separation.

\textbf{Total Loss:}
\begin{equation}
    \mathcal{L} = \mathcal{L}_{focal} + \lambda \mathcal{L}_{align}
\end{equation}
with $\lambda=0.1$.

\subsection{Runtime Defense Integration}

\subsubsection{AgentShepherd Integration}
Tools flagged as high-risk by pre-deployment analysis are converted to blocking rules:
\begin{verbatim}
rules:
  - name: block-skill-0042
    match:
      tool_name: "config_reader"
    action: block
    reason: "SkillGuard risk: 0.92"
\end{verbatim}

\subsubsection{Intrinsic Risk Sensing}
Inspired by Spider-Sense~\cite{spidersense2026}, we implement hierarchical screening:

\begin{enumerate}
    \item \textbf{Lightweight Sensing:} Fast pattern matching against known attack signatures ($<$1ms).
    \item \textbf{Deep Reasoning:} For ambiguous cases (risk $\in [0.3, 0.8]$), invoke agent's internal LLM for self-reflection.
    \item \textbf{Immediate Blocking:} High-confidence threats (risk $>0.8$) blocked without escalation.
\end{enumerate}

%==============================================================================
\section{Experimental Setup}
%==============================================================================

\subsection{Dataset}

We constructed a dataset of 1,000 agent skills:

\begin{itemize}
    \item \textbf{Benign Skills (800):} Generated using HuggingFace Upskill~\cite{upskill2026} from diverse task descriptions and scraped from public GitHub MCP repositories.
    
    \item \textbf{Malicious Skills (200):} Synthetic variations across 6 threat categories with expert validation.
\end{itemize}

Table~\ref{tab:dataset} shows the threat category distribution.

\begin{table}[t]
\centering
\caption{Dataset Composition by Threat Category}
\label{tab:dataset}
\begin{tabular}{lcc}
\toprule
\textbf{Category} & \textbf{Count} & \textbf{Percentage} \\
\midrule
Benign & 800 & 80.0\% \\
\midrule
Arbitrary Code Execution & 52 & 5.2\% \\
Data Exfiltration & 47 & 4.7\% \\
Semantic Mismatch & 33 & 3.3\% \\
Privilege Escalation & 29 & 2.9\% \\
Reverse Shell & 27 & 2.7\% \\
Supply Chain Injection & 12 & 1.2\% \\
\midrule
\textbf{Total} & \textbf{1,000} & \textbf{100\%} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Baselines}

We compare against:
\begin{itemize}
    \item \textbf{Bandit:} Rule-based Python security linter
    \item \textbf{Semgrep:} Pattern-based static analysis
    \item \textbf{Logistic Regression:} Linear classifier on our features
    \item \textbf{Random Forest:} Ensemble of decision trees
    \item \textbf{XGBoost:} Gradient boosting classifier
    \item \textbf{Spider-Sense:} State-of-the-art runtime defense
\end{itemize}

\subsection{Evaluation Metrics}

\begin{itemize}
    \item \textbf{Precision/Recall/F1:} Standard classification metrics
    \item \textbf{AUC:} Area under ROC curve
    \item \textbf{ASR:} Attack Success Rate (lower is better)
    \item \textbf{FPR:} False Positive Rate for usability
    \item \textbf{Latency:} Runtime overhead percentage
\end{itemize}

\subsection{Implementation Details}

Models trained using PyTorch 2.0 with:
\begin{itemize}
    \item Learning rate: $10^{-4}$ with cosine annealing
    \item Batch size: 32
    \item Early stopping: patience 10 epochs
    \item 5-fold cross-validation
    \item Hardware: NVIDIA RTX 3090
\end{itemize}

%==============================================================================
\section{Results}
%==============================================================================

\subsection{Main Results}

Table~\ref{tab:main_results} presents the main performance comparison.

\begin{table}[t]
\centering
\caption{Malicious Skill Detection Performance. Best results in \textbf{bold}.}
\label{tab:main_results}
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} & \textbf{AUC} \\
\midrule
Bandit & 0.82 & 0.28 & 0.44 & 0.64 \\
Semgrep & 0.85 & 0.66 & 0.80 & 0.83 \\
Logistic Regression & 0.86 & 0.78 & 0.82 & 0.89 \\
Random Forest & 0.89 & 0.84 & 0.86 & 0.92 \\
XGBoost & 0.90 & 0.86 & 0.88 & 0.94 \\
\midrule
Spider-Sense & 0.91 & 0.89 & 0.90 & 0.95 \\
\textbf{SkillGuard (Ours)} & \textbf{0.93} & \textbf{0.91} & \textbf{0.94} & \textbf{0.97} \\
\textbf{Integrated} & \textbf{0.95} & \textbf{0.94} & \textbf{0.94} & \textbf{0.98} \\
\bottomrule
\end{tabular}
\end{table}

\skillguard{} achieves 0.94 F1-score, outperforming:
\begin{itemize}
    \item Bandit by 114\% (0.44 $\rightarrow$ 0.94)
    \item Semgrep by 18\% (0.80 $\rightarrow$ 0.94)
    \item XGBoost by 7\% (0.88 $\rightarrow$ 0.94)
\end{itemize}

The integrated system (pre-deployment + runtime) achieves the best overall performance with 0.98 AUC.

\subsection{Per-Category Performance}

Fig.~\ref{fig:category_perf} shows detection recall by threat category.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{threat_category_performance}
    \caption{Detection recall by threat category. \skillguard{} shows significant improvements on semantic mismatch (+86\%) and privilege escalation (+50\%) compared to XGBoost.}
    \label{fig:category_perf}
\end{figure}

Key observations:
\begin{itemize}
    \item \textbf{Semantic Mismatch:} 86\% improvement over baseline, validating our semantic alignment features.
    \item \textbf{Privilege Escalation:} 50\% improvement from capability mismatch detection.
    \item \textbf{Reverse Shell:} High baseline performance (network patterns are distinctive).
\end{itemize}

\subsection{Ablation Study}

Table~\ref{tab:ablation} shows feature group contributions.

\begin{table}[t]
\centering
\caption{Ablation Study: Feature Group Contributions}
\label{tab:ablation}
\begin{tabular}{lcccc}
\toprule
\textbf{Configuration} & \textbf{\#Features} & \textbf{F1} & \textbf{AUC} & \textbf{$\Delta$F1} \\
\midrule
All Features & 37 & \textbf{0.94} & \textbf{0.97} & -- \\
Static Only & 29 & 0.82 & 0.89 & -0.12 \\
Semantic Only & 8 & 0.71 & 0.82 & -0.23 \\
No Obfuscation & 29 & 0.88 & 0.93 & -0.06 \\
No Data Flow & 34 & 0.90 & 0.94 & -0.04 \\
No Embedding Align. & 36 & 0.85 & 0.91 & -0.09 \\
\bottomrule
\end{tabular}
\end{table}

Key findings:
\begin{itemize}
    \item Removing semantic features causes 23\% F1 drop, confirming their importance.
    \item Embedding alignment contributes 9\% to performance.
    \item All feature groups provide complementary signal.
\end{itemize}

\subsection{Feature Importance}

Fig.~\ref{fig:feature_importance} shows the top 15 most important features.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{feature_importance}
    \caption{Top 15 feature importances. Dangerous primitives (\texttt{has\_subprocess}, \texttt{has\_eval\_exec}) and semantic features (\texttt{semantic\_mismatch}, \texttt{embedding\_cosine\_sim}) dominate.}
    \label{fig:feature_importance}
\end{figure}

The most important features are:
\begin{enumerate}
    \item \texttt{has\_subprocess} (0.142): Shell execution is highly indicative
    \item \texttt{has\_eval\_exec} (0.128): Dynamic code execution
    \item \texttt{semantic\_mismatch} (0.115): Our novel semantic feature
    \item \texttt{has\_socket} (0.098): Network operations
    \item \texttt{embedding\_cosine\_sim} (0.087): Description-code alignment
\end{enumerate}

\subsection{Runtime Defense Comparison}

Table~\ref{tab:runtime} compares defense configurations.

\begin{table}[t]
\centering
\caption{Multi-Layer Defense Comparison}
\label{tab:runtime}
\begin{tabular}{lccc}
\toprule
\textbf{Configuration} & \textbf{ASR $\downarrow$} & \textbf{FPR $\downarrow$} & \textbf{Latency} \\
\midrule
SkillGuard (Pre-deploy) & 25\% & 5\% & 0\% \\
AgentShepherd (Runtime) & 15\% & 8\% & 5\% \\
Spider-Sense (Runtime) & 5\% & 2\% & 8.3\% \\
\textbf{Integrated (Both)} & \textbf{3\%} & \textbf{3\%} & 10\% \\
\bottomrule
\end{tabular}
\end{table}

The integrated defense achieves:
\begin{itemize}
    \item 88\% reduction in ASR compared to pre-deployment only
    \item 40\% reduction compared to AgentShepherd alone
    \item Acceptable latency overhead (10\%)
\end{itemize}

\subsection{ROC and Precision-Recall Curves}

Fig.~\ref{fig:roc} shows ROC curves for all methods.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{roc_curves}
    \caption{ROC curves comparing \skillguard{} with baselines. Our method achieves 0.97 AUC, significantly outperforming rule-based tools.}
    \label{fig:roc}
\end{figure}

%==============================================================================
\section{Discussion}
%==============================================================================

\subsection{Why Semantic Features Matter}

Our results demonstrate that semantic alignment features are crucial for detecting sophisticated Trojans. Rule-based tools like Bandit achieve only 28\% recall because they cannot capture the disconnect between a tool's stated purpose and its actual behavior.

The semantic mismatch feature alone contributes 11.5\% to model importance---the third most important feature after explicit dangerous primitive detection.

\subsection{Defense-in-Depth is Essential}

Pre-deployment analysis alone achieves 75\% ASR reduction. Adding runtime defense brings this to 97\%. This validates the defense-in-depth approach: some attacks evade static analysis but are caught at runtime.

The integrated system maintains low false positives (3\%) while achieving near-complete attack prevention, making it practical for production deployment.

\subsection{Limitations}

\begin{enumerate}
    \item \textbf{Synthetic Data:} Our malicious samples are synthetically generated. Real-world Trojans may exhibit different patterns.
    
    \item \textbf{Adversarial Robustness:} Sophisticated attackers may craft Trojans that specifically evade our features. Future work should evaluate against adaptive attackers.
    
    \item \textbf{Language Coverage:} Current implementation focuses on Python. Extension to JavaScript and other languages requires additional feature engineering.
    
    \item \textbf{Latency:} The 10\% overhead may be significant for latency-sensitive applications.
\end{enumerate}

\subsection{Future Work}

Promising directions include:
\begin{itemize}
    \item Collecting real-world malicious tools for evaluation
    \item Adversarial training against evasion attacks
    \item Multi-language support
    \item Integration with LLM-based reasoning for explainability
\end{itemize}

%==============================================================================
\section{Conclusion}
%==============================================================================

We presented \skillguard{}, a multi-layer defense framework against semantic Trojans in AI agent tool chains. By combining novel semantic features with established static analysis and integrating pre-deployment ML with runtime protection, we achieve 0.94 F1-score and reduce attack success rate to 3\%.

Our key insight is that semantic Trojans require semantic defenses. Static pattern matching is insufficient when attackers deliberately obscure the connection between declared and actual functionality. The combination of embedding-based alignment detection, dangerous primitive analysis, and runtime filtering provides robust protection.

As AI agents become more prevalent in production systems, securing their tool ecosystems is critical. \skillguard{} provides a practical, deployable solution that significantly raises the bar for attackers while maintaining acceptable overhead for legitimate use.

\section*{Acknowledgment}

We thank the anonymous reviewers for their valuable feedback. This work was supported in part by [funding sources redacted for blind review].

%==============================================================================
% References
%==============================================================================

\begin{thebibliography}{20}

\bibitem{langchain2023}
H. Chase, ``LangChain: Building applications with LLMs through composability,'' 2023. [Online]. Available: https://github.com/langchain-ai/langchain

\bibitem{autogpt2023}
S. Nakajima, ``Auto-GPT: An Autonomous GPT-4 Experiment,'' 2023. [Online]. Available: https://github.com/Significant-Gravitas/Auto-GPT

\bibitem{mcp2024}
Anthropic, ``Model Context Protocol Specification,'' 2024. [Online]. Available: https://github.com/modelcontextprotocol

\bibitem{google_saif2023}
Google, ``Secure AI Framework (SAIF),'' 2023. [Online]. Available: https://safety.google/cybersecurity-advancements/saif/

\bibitem{anthropic_tools2024}
Anthropic, ``Tool Use with Claude,'' 2024. [Online]. Available: https://docs.anthropic.com/claude/docs/tool-use

\bibitem{agentshepherd2026}
Z. Chen, Y. Chen, B. Jiang, and Z. Xu, ``AgentShepherd: A Transparent Gateway for AI Agents,'' 2026. [Online]. Available: https://github.com/AgentShepherd/agentshepherd

\bibitem{spidersense2026}
Z. Yu, Z. Yang, \textit{et al.}, ``Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense,'' \textit{arXiv preprint arXiv:2602.05386}, 2026.

\bibitem{upskill2026}
HuggingFace, ``Upskill: Generate and Evaluate Agent Skills,'' 2026. [Online]. Available: https://github.com/huggingface/upskill

\bibitem{neuralcleanse2019}
B. Wang, \textit{et al.}, ``Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks,'' in \textit{Proc. IEEE S\&P}, 2019.

\bibitem{abs2019}
Y. Liu, \textit{et al.}, ``ABS: Scanning Neural Networks for Back-doors by Artificial Brain Stimulation,'' in \textit{Proc. CCS}, 2019.

\bibitem{devign2019}
Y. Zhou, \textit{et al.}, ``Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks,'' in \textit{Proc. NeurIPS}, 2019.

\bibitem{vuldeepecker2018}
Z. Li, \textit{et al.}, ``VulDeePecker: A Deep Learning-Based System for Vulnerability Detection,'' in \textit{Proc. NDSS}, 2018.

\bibitem{bandit2023}
OpenStack, ``Bandit: Security oriented static analyser for Python code,'' 2023. [Online]. Available: https://github.com/PyCQA/bandit

\bibitem{semgrep2023}
r2c, ``Semgrep: Lightweight static analysis for many languages,'' 2023. [Online]. Available: https://semgrep.dev/

\bibitem{codeql2023}
GitHub, ``CodeQL: Semantic code analysis engine,'' 2023. [Online]. Available: https://codeql.github.com/

\bibitem{codebert2020}
Z. Feng, \textit{et al.}, ``CodeBERT: A Pre-Trained Model for Programming and Natural Languages,'' in \textit{Proc. EMNLP}, 2020.

\end{thebibliography}

%==============================================================================
% Author Biographies (placeholder for camera-ready)
%==============================================================================

\begin{IEEEbiographynophoto}{Anonymous Author 1}
Biography withheld for blind review.
\end{IEEEbiographynophoto}

\begin{IEEEbiographynophoto}{Anonymous Author 2}
Biography withheld for blind review.
\end{IEEEbiographynophoto}

\end{document}
